**Welcome to the Lir Tutorial**

To make best use of this tutorial, open the source file `anagrams.lir`
(available in the [repository of the
tutorial](https://github.com/borisvassilev/lir-tutorial)) in a text
editor and start reading.  Every time you see a "`----`" on a line by
itself, it is a good time to stop reading for a moment and try to
compile the source file up to that point.  This can be done by simply
invoking `lir` with the file as its only argument:

~~~~
$ lir anagrams.lir
~~~~

If everything goes well, a final document, `anagrams.html`, will be
generated in your working directory.  Open it in your web browser!

The file up to here is just a plain text file, formatted using the
"markdown" markup recognized by Pandoc.  The whole first line is surrounded
by double asterisk (`**`) for strong emphasis.  In the first paragraph,
there is inline code surrounded by single backticks (`` ` ``).  We see a
single-line block of source code verbatim; usually, this is not necessary
in a Lir source file.

Now let's try to generate the first version of the final document:

- You can copy everything up to (and including) the 4-dash line below to
  file named `anagrams.lir` in your working directory.
- You can also use the link below to download this file.
- For `git` users: you can use the version of `anagrams.lir` in this
  repository in the tag `tag-01`.

Now, run Lir.  Notice how the list above was correctly recognized and
typeset differently.

Get [source](https://github.com/borisvassilev/lir-tutorial/docs/1/anagrams.lir) and [final document](https://borisvassilev.github.io/lir-tutorial/1/anagrams.html)


----

# Document formatting and structure
The previous part contains a few examples of using markdown to format your
text.  In this part, we will see more uses of markdown.  At the beginning
of this paragraph, there is a line starting with a hash sign (`#`).  This
defines a section heading: in the final document, "Document formatting and
structure" will be typeset differently, and it will appear in a table of
contents at the beginning of the document.

First, let's give our data analysis an aim and a name.  We want to find
anagrams of words in the English language.  We will call the data analysis
"Anagrams", and give our name as an author.

---
title: 'Lir Tutorial: Finding Anagrams'
author: Boris Vassilev
...

(This will not appear in the final document at that spot: it will be used
to create the document title.)

## Sections and subsections
By using 1, 2, or 3 hash signs at the beginning of the line, we define
sections, subsections, subsubsections in the final document.

## Links
Here is a [link to the Pandoc User's Guide](http://pandoc.org/MANUAL.html).
I usually need to keep this guide open while I'm writing a Lir source file.

# Making the final document
In order to be able to use Lir efficiently, you need to learn at least a
bit about the program Make and the syntax of Makefiles.  Here, we will
define a Makefile for our data analysis.  It tells make
that to make all files, it needs to generate the file `anagrams.html` by
running the program `lir` with `anagrams.lir` as its first and only
argument. 
<<Makefile>>=
name = anagrams

all: $(name).html

$(name).html: $(name).lir
	lir $(name).lir

@
This is our first code chunk. Its name is "Makefile"; its contents begin on
the line after its declaration and run up to the `@` on a
line by itself. The contents of this code chunk can go to the file named
`Makefile` in the working directory of the project. To do this, we could
use the following invocation of `notangle`, part of the Noweb distribution:

~~~~
$ notangle -t8 -RMakefile anagrams.lir > Makefile
~~~~

> Run `notangle`; leave tabs untouched; extract the code chunk named
> "Makefile" from the source file `anagrams.lir` to the file `Makefile`.

Usually, we don't have to do this on our own: Lir recognizes code chunks
that should be extracted to files, and does that automatically.

Get [source](https://github.com/borisvassilev/lir-tutorial/docs/2/anagrams.lir) and [final document](https://borisvassilev.github.io/lir-tutorial/2/anagrams.html)


----

# Aim
The aim of this tutorial is to show you how to use Lir efficiently and
effectively.  To achieve this, the tutorial describes the solution to a
simple problem: how to find anagrams in the English language.

The idea is to follow the solution outlined by Bentley in "Programming
Pearls" [@bentley1986programming].  We are going to prepare a dictionary of
words, calculate the signature of each word, sort by signatures.  At that
point, all sets of words that are anagrams of each other will be in
consecutive runs, signed by the same signature.  We will squash them, each
set (with more than two words in it) displayed on a space-separated line.

Now, we are going to define our first special code chunk.  If the name of
the code chunk is prefixed by "`source:`", this declares the name of a file
that is necessary in order to generate the final document.  Here, we need
to declare that we are using the file `anagrams.bib`, which contains the
bibliography for this document. In the previous paragraph, we have cited the
1986 book "Programming Pearls" using the "`[@<bibkey>]`" markdown.

From now on, the document will end with the beginning of a last section,
"Bibliography".

Get [source](https://github.com/borisvassilev/lir-tutorial/docs/3/anagrams.lir) and [final document](https://borisvassilev.github.io/lir-tutorial/3/anagrams.html)


----

# Dictionary
What is a dictionary that is useful as input to our program?  What exactly
is the program going to do?  We want to find a signature for every word in
the dictionary.  To do that, we will sort the characters of each word.  If
a two different words have the same signature, this means they have the
exact same letters, so, they are anagrams of each other.

I will use [the dictionary available with the Linux
distribution](/usr/share/dict/words).  This file was copied to the working
directory under the name `en-dict`, and declared as an input file (source).
<<:source en-dict>>=
@

This dictionary is meant to be used by other programs, for example to check
spelling.  It contains duplicate version of many words, only with the first
letter capitalized or suffixed by an "'s".  To get rid of these duplicates,
we define a bash script.  It contains three components in a pipe:

<<clean-en-dict.sh>>=
<<Set all letters to lower case>> \
        | <<Delete 's at the end of words>> \
        | <<Sort, leaving only unique entries>>
@
The first "normal" code chunk [[<<clean-en-dict.sh>>]] is used to define
the pipe that cleans the dictionary file. It is a root chunk: it is not
referenced by name in any other code chunk. It contains references to other
code chunks by name.

The first chunk referenced above is [[<<Set all letters to lower case>>]].
It is a call to a SWI-Prolog script that converts all letters to lower
case.
<<Set all letters to lower case>>=
<<Run SWI-Prolog script>> to-lower-case.prolog
@
The script [[<<to-lower-case.prolog>>]] has to be declared as a dependency
of the Bash script that uses it:
<<:make>>=
clean-en-dict.sh: to-lower-case.prolog

@
The SWI-Prolog script reads all input, converts it to lower case, and
writes it to output.
<<to-lower-case.prolog>>=
main :-
        read_string(current_input, _, Input),
        string_lower(Input, Output),
        format(current_output, "~s", [Output]).
@
To safely run this and any Prolog program that defines a `main`, we can do:
<<Run SWI-Prolog script>>=
swipl -q -O -g 'main,halt' -t 'halt(1)'
@

In the next component of the pipeline, a call to `sed` removes all trailing
"'s".
<<Delete 's at the end of words>>=
sed "s/'s$//"
@

At the end, everything is sorted, leaving only unique entries.
<<Sort, leaving only unique entries>>=
sort --unique
@

We define the transformation from the original file `en-dict` to the
cleaned `en-words` as another rule:
<<:make>>=
en-words: en-dict clean-en-dict.sh
	bash clean-en-dict.sh < $< > $@

@

The first line of this rule reads:

> To generate the file `en-words`, you need the files `en-dict` and
> `clean-en-dict.sh`.

The second line of the rule reads:

> Run the bash script `clean-en-dict.sh` to convert the first prerequisite
> `en-dict` (written as `$<`) to create the target `en-words` (written as
> `$@`).

There is an empty line after the second line: it is necessary in order to
finish the rule.

Finally, to have a vague idea if this all worked, we can add a display item
with the sizes of the original and the cleaned dictionary.  Immediately
below the placeholder for the listing is the rule for generating the result
using `wc`.
<<:listing en-sizes>>=
title: Word file sizes.
<<:make>>=
en-sizes: en-words en-dict
	wc --lines $^ > $@

@

Get [source](https://github.com/borisvassilev/lir-tutorial/docs/4/anagrams.lir) and [final document](https://borisvassilev.github.io/lir-tutorial/4/anagrams.html)


----

# Bibliography
